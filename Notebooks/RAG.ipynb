{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbc547e-b297-4279-ab40-51205611c57f",
   "metadata": {},
   "source": [
    "# Retreival Augmented Generation\n",
    "Combine the capabilities of large language models with external data retrieval\n",
    "\n",
    "Ehances language models performance by providing access to specific data that the pre-trained model's general knowledge lacks\n",
    "\n",
    "The effectiveness of LLM RAG diminishes significantly when the augmented data is already common knowledge and inherently included in the foundation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a02edd-d927-45df-82a3-f8101563db6a",
   "metadata": {},
   "source": [
    "Step 1 : Load the data. Examples here for CSV, PDF and HTML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d29e6e-1c01-46dd-b14d-42ee2ad17ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "csv_loader = CSVLoader(file_path = 'data/Questions.csv')\n",
    "docs1 = csv_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2658185-c158-4c14-888f-769315cdbe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader(file_path='data/Resume_Checklist.pdf')\n",
    "docs2 = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaee6edf-dad5-4546-ae5c-6a56ec03d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "html_loader = UnstructuredHTMLLoader(file_path='data/NationalAIStrategy.html', mode='single', strategy='fast')\n",
    "docs3 = html_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70134bfe-cee0-40ff-9b10-a68f42d9c6bd",
   "metadata": {},
   "source": [
    "Example of how you can reference instances of documents - content and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6b95ed-125e-4148-9eb0-74219cf2d933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/NationalAIStrategy.html'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document = docs3[0]\n",
    "first_document.metadata\n",
    "# first_document.page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9847eb-f918-42e3-ab49-b84041d52e9a",
   "metadata": {},
   "source": [
    "Step 2 : Split the documents into chunks that can be quickly retreived and integrated into the model prompt. A chunk needs to be useful to the LLM. Larger not always better. Choose the chunk size parameter wisely. Also, need to make sure that we don't lose information between chunks. Set the chunk overlap parameter to include information beyond the boundary\n",
    "\n",
    "Different approaches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ca806b-f58f-4d50-af45-f5e5f31226fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4255, which is longer than the specified 1000\n",
      "Created a chunk of size 1161, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "# Separates the chunks by paragraph. Often too long\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=1000, chunk_overlap=10)\n",
    "chunks = text_splitter.split_text(first_document.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02d9907-efda-44cd-b317-99ee6780d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# If the first separator results in chunks longer than chunk size, will use the next one, and so on\n",
    "text_splitter2 = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter2.split_text(first_document.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f378e132-4006-491c-ab28-519edc4ed8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "# An example where you are splitting a document rather than text\n",
    "chunks = splitter.split_documents(docs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bfc99a-6f3e-4b6f-b9e3-cb6ecd0a65ca",
   "metadata": {},
   "source": [
    "Step 3 : Now we have split the documents into chunks, we need to embed and store them for retreival\n",
    "\n",
    "Embeddings are representations of the text as vectors in a high dimensional vector space. Similar text is stored together within this space \n",
    "\n",
    "Vector stores are databases designed to store this high dimensional vector data\n",
    "\n",
    "When we receive a user input, it will itself be embedded and used to query the database. The most similar documents will then be returned\n",
    "using the Chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69ec018d-3ea3-4cbc-b963-3ec5982dff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df66a30-82e9-433d-b35d-dd0d5105917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "# If we used the split_text method, would use Chroma.from_text below\n",
    "vector_store = Chroma.from_documents(documents=chunks, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691459d1-888c-4dd4-9890-6ba1edc16ccb",
   "metadata": {},
   "source": [
    "Pulling this together then, we need to define three components:\n",
    "\n",
    "A retreiver : Takes the user input and retreives the relavent document chunks\n",
    "\n",
    "A prompt : To combine the user input and document chunks\n",
    "\n",
    "Our LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2903e2e-837d-4335-902e-fc3ef4ea6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The arguments specify what sort of search to perform and how moany chunks to retreive per query\n",
    "retriever = vector_store.as_retriever(search_type = 'similarity', search_kwargs={'k': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "720bab2e-23ce-41b1-baa5-6c589c1e11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, say that you don't know.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231deb23-fe69-4995-889b-e1a5fec83dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc3916-1b64-44c4-8298-bfa4d06e6a97",
   "metadata": {},
   "source": [
    "We can now define our RAG chain\n",
    "\n",
    "Runnable Pass Through just passes through the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8564749d-3687-4a1d-8340-dca4f6d410c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "    {'context': retriever, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9339aa-3250-478c-b9c6-784374c05e0a",
   "metadata": {},
   "source": [
    "And using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "216bfd72-d3bb-421e-a8a6-76fe3c7f478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The advice regarding what not to include in your resume is to avoid sections that are not directly relevant to a Data Science position. Specifically, you should leave off sections such as hobbies, volunteer experience, and interests, as they can make your resume lengthy and distract from the important information. Additionally, you should minimize abbreviations, remove redundant phrases, avoid too much technical jargon, and ensure there are no typos.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('What is the advice as to what not to include in your resume?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b68b71-3b64-4d60-82d6-9631813c19ad",
   "metadata": {},
   "source": [
    "Note re debugging : Use LangSmith\n",
    "\n",
    "I was getting an I don't know answer and wanted to see the prompt that went into the LLM\n",
    "\n",
    "Looking in LangSmith, everything was working but no content was getting provided as the chunk size was too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a4e93-0aaa-4b63-a78b-f97dc5876bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
